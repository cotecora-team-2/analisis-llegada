---
title: "Simulación de tiempos de llegada"
output: html_document
editor_options: 
  markdown: 
    wrap: 80
---

```{r setup, include=FALSE, message = FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
theme_set(theme_minimal(base_size = 13))
knitr::opts_chunk$set(echo = TRUE)
# paquetes y codigo 
library(patchwork)
library(survival)
library(survminer)

estados <- c("ZAC", "COL", "CHIH", "MICH", "NAY", "BC", "BCS", "SON",
             "SIN", "NL", "SLP", "QRO", "GRO", "TLAX", "CAMP")
source("./simulacion_tiempos.R")
source("./lectura_procesamiento.R")
```

## Datos

Utilizaremos los datos de la elección presidencial de 2018.

-   Muestra seleccionada para el conteo rápido.
-   Remesas de la muestra seleccionada, hasta media noche.
-   Tabla de cómputos distritales por casilla

## Idea para simulación

1.  Construir para cada estado un modelo para los tiempos de llegada de las
    casillas según los datos de remesas, en términos de lista nominal, tipo de
    casilla, porcentaje de votos obtenidos para los candidatos y otras
    variables.
2.  Seleccionar una muestra nueva a partir de la tabla de conteos distritales y
    según el diseño.
3.  Simular tiempos de llegada según el modelos construido en 1)

Con estas simulaciones podemos entonces

4.  Evaluar propiedades de estimadores (por ejempĺo cobertura para intervalos, o
    sesgo para estimadores puntuales) dependiendo de la hora de corte, o cortes
    basados en % de casillas recibidas en las remesas simuladas.

En esta versión, consideramos la estimación de proporción de votos para un
candidato usando el estimador de razón combinado bajo muestreo estratificado
según distrito federal. 

## Modelos de tiempo de llegada

-   Usamos modelos paramétricos de supervivencia (*survreg*) para los tiempos de
    llegada de las casillas, pues una fracción de la muestra
-   Estos modelos son estratificados por estado, y usamos
    tiempos de llegada log-logísticos.

```{r}
estados %>% sort 
length(estados)
```

### Componentes

```{r}
comps_1$rotation[,1:2] %>%
  as.data.frame() %>% 
  add_rownames() %>%
  arrange(PC2) %>% 
  mutate(across(where(is.numeric), ~ round(., 2))) %>% 
  print(n = 20)
```



```{r, echo = FALSE}
llegadas_tbl_2 <- llegadas_tbl %>% 
  filter(state_abbr %in% estados) %>%
  ungroup %>% 
  mutate(tiempo_huso = ifelse(tiempo - huso > 0, 
                              tiempo - huso, 0.001)) %>% 
  mutate(ln_log_c = lista_nominal_log - mean(lista_nominal_log)) %>% 
  rowwise() %>% 
  mutate(brecha = pmax(AMLO_1, RAC_1, JAMK_1) - median(c(AMLO_1, RAC_1, JAMK_1)))
formula <- as.formula("Surv(tiempo_huso, status) ~ 1 +
      ln_log_c + 
      tipo_casilla + 
      #factor(tipo_seccion) + 
      tipo_casilla + 
      state_abbr:.fittedPC1 +
      state_abbr:.fittedPC2 +
      state_abbr:log(1 + brecha) + 
      #state_abbr:I(log((1+ VPH_CEL) / (2 + TVIVPARHAB))) +
      #state_abbr:log((1 + abs(AMLO_1 - RAC_1))/( 1 + TOTAL_VOTOS_CALCULADOS)) +
      #state_abbr:log((1 + abs(AMLO_1 - JAMK_1))/( 1 + TOTAL_VOTOS_CALCULADOS)) +
      state_abbr:log((1+RAC_1)/(TOTAL_VOTOS_CALCULADOS + 1)) + 
      state_abbr:log((1+AMLO_1)/(TOTAL_VOTOS_CALCULADOS + 1)) +
      state_abbr:log((1+JAMK_1)/(TOTAL_VOTOS_CALCULADOS +  1)) +
      state_abbr:ln_log_c + 
      strata(state_abbr)")
reg_2 <- survreg(formula = formula, 
    llegadas_tbl_2, 
    dist='loglogistic', 
    control = survreg.control(maxiter = 5000))
```

Los coeficientes y escalas para cada estado son:

```{r}
reg_2 %>% tidy() %>%  
  mutate(across(is.numeric, ~round(., 3))) %>%
  DT::datatable()
```

```{r}
coefs_1 <- reg_2 %>% tidy() %>% 
  filter(str_detect(term, "PC")) %>% 
  separate(term, into = c("estado", "variable"), sep = ":") %>% 
  mutate(variable = str_sub(variable, 5, 20)) %>%
  mutate(estado = str_sub(estado, 11, 30)) %>% 
  group_by(variable) %>% 
  mutate(estado = fct_reorder(estado, estimate))
ggplot(coefs_1, aes(x = estado, y = estimate, 
                    ymin = estimate - std.error,
                    ymax = estimate + std.error)) + 
  geom_hline(yintercept = 0, colour = "salmon") +
  geom_point() +
  geom_linerange() +
  facet_wrap(~ variable) + coord_flip()
```


### Diagnósticos

Checamos simulaciones del modelo con la misma muestra para ver el ajuste a
total. En gris están las simulaciones y en rojo los datos observados de las
remesas:

```{r, echo = FALSE, fig.width=8, fig.height=10}
datos_sim <- map(1:70, ~ simular_cuantiles(.x, llegadas_tbl_2, reg = reg_2)) 
gg_obs <- ggsurvplot(survfit(Surv(tiempo_huso, status)~ state_abbr, llegadas_tbl_2))
datos_obs <- gg_obs$data.survplot %>% mutate(id = 71)
datos_check <- bind_rows(datos_obs, datos_sim)
ggplot(datos_check %>% filter(id!=71), aes(x = time, y = surv, group = id)) +
  geom_hline(yintercept = 0.50, colour = "gray") +
  geom_step( alpha = 0.3, colour = "gray") +
  geom_step(data = datos_check %>% filter(id==71), colour = "red") +
  facet_wrap(~ strata) 
```

## Evaluación de tamaño de muestra y hora de salida

Ahora simulamos muestras de distintos tamaños, con horas de llegada. Hacemos
cortes en distintos tiempos, y **evaluamos en cada hora de salida el sesgo, 
varianza y error cuadrático medio de los estimadores puntuales**.


```{r}
# cortes (horas después de 18:30 en la elección de 2018)
cortes <- c(1.5, 2.5, 3, 3.5, 4, 4.5, 5.5, Inf)
# tamaño de muestra
props_muestra <- c(0.03, 0.05, 0.10)
estado_sim <- "NL"
```

```{r, echo = FALSE}
sim_1 <- simular_cortes(1, cortes = cortes, prop_muestra = 0.05, 
                        estado_sim = estado_sim)
sim_1
```

```{r}
eval_tbls <- parallel::mclapply(props_muestra, function(x) {
    map_df(1:600, ~ simular_cortes(.x, cortes= cortes, prop_muestra = x, estado_sim = estado_sim))
  },  mc.cores = 3)
```

```{r, echo = FALSE}
evals_tbl <- bind_rows(eval_tbls)
```

En primer lugar, **el error cuadrático medio es menor si se selecciona una
muestra inicial más grande**, y se reduce conforme la hora de censura es más
tarde:

```{r, echo = FALSE}
total <- seleccionar_muestra(conteo, prop = 1, estado_sim)
prop_obs_tbl <- total %>% 
  #filter(!is.na(TVIVHAB)) %>% 
  pivot_longer(cols = all_of(c("AMLO_1", "RAC_1", "JAMK_1")), 
               names_to = "candidato", values_to ="num_votos") %>% 
  group_by(candidato, state_abbr) %>% 
  summarise(acumulado_cand = sum(num_votos), 
            acumulado_tot = sum(TOTAL_VOTOS_CALCULADOS),
            .groups = "drop") %>% 
  mutate(prop_obs = acumulado_cand / acumulado_tot) %>% 
  select(state_abbr, candidato, prop_obs)
prop_obs_tbl
```

```{r, echo = FALSE}
ecm_tbl <- evals_tbl %>% 
  left_join(prop_obs_tbl) %>% 
  ungroup() %>% 
  group_by(corte, prop_muestra, candidato) %>% 
  summarise(sesgo = mean(prop_cand) - mean(prop_obs),
            varianza = var(prop_cand)) %>% 
  ungroup %>% 
  mutate(recm = sqrt(sesgo^2 + varianza)) %>% 
  mutate(prop_muestra = factor(prop_muestra))
ecm_tbl <- ecm_tbl %>% 
  mutate(corte_f = factor(corte))
```

```{r, echo = FALSE, fig.height = 4, fig.width = 10}
ggplot(ecm_tbl, aes(x = corte, y = recm, 
                    colour = prop_muestra, 
                    group = prop_muestra)) +
  geom_vline(xintercept = 4, colour = "gray30") +
  geom_point() + geom_line() +
  ylab("Raíz de Error Cuadrático Medio") + 
  xlab("Hora de censura (horas después de 18:30)") +
  facet_wrap(~candidato)
```

Sin embargo, la **proporción del error que se debe a sesgo es más grande cuanto
más grande sea la muestra inicial**:

```{r, echo = FALSE, fig.height = 4, fig.width = 10}
ggplot(ecm_tbl, aes(x = corte, y = (sesgo) / sqrt(varianza), 
                    colour = prop_muestra, 
                    group=prop_muestra)) +
  geom_vline(xintercept = 4, colour = "gray50") +
  geom_point() + geom_line() + 
  ylab(expression(Sesgo / EE)) + 
  xlab("Hora de censura (horas después de 18:30)") +
  facet_wrap(~candidato)
```

```{r, echo = FALSE, fig.height = 4, fig.width = 10}
ecm_tbl %>% filter(corte == 4) %>%
  mutate(ee = sqrt(varianza)) %>% 
  select(corte, prop_muestra, candidato, sesgo, ee) %>% 
  arrange(candidato, prop_muestra)
```

## Puntos de corte y proporción de sesgo: estados de elección 2021



```{r, cache = TRUE}
library(parallel)
sims_estados <- mclapply(estados, function(estado_sim){
  print(estado_sim)
  # simular
  eval_tbl_1 <- map_df(1:400, ~ simular_cortes(.x, cortes= cortes, prop_muestra = 0.03,
                                             estado_sim = estado_sim))
  eval_tbl_2 <- map_df(1:400, ~ simular_cortes(.x, cortes= cortes, prop_muestra = 0.05,
                                             estado_sim = estado_sim))
  eval_tbl_3 <- map_df(1:400, ~ simular_cortes(.x, cortes= cortes, prop_muestra = 0.10,
                                             estado_sim = estado_sim))
  evals_tbl <- bind_rows(eval_tbl_1, eval_tbl_2, eval_tbl_3)
  
  # proporciones de cómputos
  total <- seleccionar_muestra(conteo, prop = 1, estado_sim)
  prop_obs_tbl <- total %>% 
    pivot_longer(cols = all_of(c("AMLO_1", "RAC_1", "JAMK_1")), 
               names_to = "candidato", values_to ="num_votos") %>% 
    group_by(candidato, state_abbr) %>% 
    summarise(acumulado_cand = sum(num_votos), 
            acumulado_tot = sum(TOTAL_VOTOS_CALCULADOS),
            .groups = "drop") %>% 
    mutate(prop_obs = acumulado_cand / acumulado_tot) %>% 
    select(state_abbr, candidato, prop_obs)
  # calcular sesgo, varianza y proporción de muestra.
  ecm_tbl <- evals_tbl %>% 
    left_join(prop_obs_tbl, by = "candidato") %>% 
    ungroup() %>% 
    group_by(corte, prop_muestra, candidato) %>% 
    summarise(sesgo = mean(prop_cand) - mean(prop_obs),
            varianza = var(prop_cand),
            prop_casillas_muestra = mean(prop_casillas_muestra), 
            .groups = "drop") %>% 
    mutate(recm = sqrt(sesgo^2 + varianza)) %>% 
    mutate(sesgo_relativo = abs(sesgo) / sqrt(varianza)) %>% 
    mutate(prop_muestra = factor(prop_muestra)) %>% 
    mutate(state_abbr = estado_sim)
  ecm_tbl
}, mc.cores = 6)
```

```{r}
sims_estados <- sims_estados %>% bind_rows()
```


```{r, fig.width = 10}
ggplot(sims_estados %>% filter(candidato == "RAC_1"),
       aes(x = prop_casillas_muestra, y = sesgo_relativo, colour = prop_muestra)) +
  geom_hline(yintercept = 0.5) +
  geom_point() + geom_line() + 
  facet_wrap(~state_abbr) 
```




## Estimaciones finales vs conteos

**Obs**: las estimaciones de abajo no utilizan la estratificación (corregir).

```{r}
prop_obs_tbl <- conteo %>% 
  pivot_longer(cols = all_of(c("AMLO_1", "RAC_1", "JAMK_1")), 
               names_to = "candidato", values_to ="num_votos") %>% 
  group_by(candidato, state_abbr) %>% 
  summarise(acumulado_cand = sum(num_votos, na.rm = T), 
            acumulado_tot = sum(TOTAL_VOTOS_CALCULADOS, na.rm = T),
            num_casillas = n(),
            .groups = "drop") %>% 
  mutate(prop_obs = acumulado_cand / acumulado_tot) %>% 
  select(state_abbr, candidato, prop_obs, num_casillas)
prop_obs_tbl
```

```{r}
prop_muestra_tbl <- llegadas_tbl %>% 
  filter(tiempo < 3) %>% 
  pivot_longer(cols = all_of(c("AMLO_1", "RAC_1", "JAMK_1")), 
               names_to = "candidato", values_to ="num_votos") %>% 
  group_by(candidato, state_abbr) %>% 
  summarise(acumulado_cand = sum(num_votos, na.rm = T), 
            acumulado_tot = sum(TOTAL_VOTOS_CALCULADOS, na.rm = T),
            .groups = "drop") %>% 
  mutate(prop_muestra = acumulado_cand / acumulado_tot) %>% 
  select(state_abbr, candidato, prop_muestra)
prop_muestra_tbl
```

```{r}
comparacion_tbl <- left_join(prop_obs_tbl, prop_muestra_tbl) %>% 
  mutate(dif = 100*(prop_muestra - prop_obs)) %>% 
  ungroup %>% 
  group_by(candidato) %>% 
  arrange(candidato, dif) %>%
  mutate(across(is.numeric, ~ round(., 3))) 
comparacion_tbl %>% 
  DT::datatable()
```

```{r}
ggplot(comparacion_tbl, aes(x = candidato, y = dif, size = num_casillas)) +
  geom_jitter(width = 0.1, height = 0.0) + 
  stat_summary(fun = mean, geom = "point", 
               shape = 20, size = 8, color = "red", fill = "red") +
  coord_flip() + geom_hline(yintercept = 0, colour = "red") +
  ylab("Diferencia Computos (Muestra obs vs Total)") 
```


