---
title: "Simulación de tiempos de llegada"
output: html_document
editor_options: 
  markdown: 
    wrap: 80
---

```{r setup, include=FALSE, message = FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
theme_set(theme_minimal(base_size = 13))
knitr::opts_chunk$set(echo = TRUE)
# paquetes y codigo 
library(lubridate)
library(patchwork)
library(survival)
library(survminer)
library(ggfortify)
estados <- c("ZAC", "COL", "CHIH", "MICH", "NAY", "BC", "BCS", "SON",
             "SIN", "NL", "SLP", "QRO", "GRO", "TLAX", "CAMP")
source("./simulacion_tiempos.R")
source("./lectura_procesamiento.R")
```

## Datos

Utilizaremos los datos de la elección presidencial de 2018.

-   Muestra seleccionada para el conteo rápido.
-   Remesas de la muestra seleccionada, hasta media noche.
-   Tabla de conteos distritales por casilla

## Idea para simulación

1.  Construir para cada estado un modelo para los tiempos de llegada de las
    casillas según los datos de remesas, en términos de lista nominal, tipo de
    casilla, porcentaje de votos obtenidos para los candidatos y otras
    variables.
2.  Seleccionar una muestra nueva a partir de la tabla de conteos distritales y
    según el diseño.
3.  Simular tiempos de llegada según 1)
4.  Evaluar propiedades de estimadores (por ejempĺo cobertura para intervalos, o
    sesgo para estimadores puntuales) dependiendo de la hora de corte, o cortes
    basados en % de casillas recibidas en las remesas simuladas.

En esta versión, consideramos la estimación de proporción de votos para un
candidato, y por el momento usamos muestreo aleatorio simple para ilustrar.

## Modelos de tiempo de llegada

-   Usamos modelos paramétricos de supervivencia (*survreg*) para los tiempos de
    llegada de las casillas, pues una fracción de la muestra
-   Estos modelos son estratificados por estado, y en este ejemplo usamos
    tiempos de llegada log-normales.
-   Algunos diagnósticos del ajuste están en la siguiente sección

```{r}
estados %>% sort 
length(estados)
```

```{r, echo = FALSE}
library(broom)
media_ln_log  <- mean(llegadas_tbl$lista_nominal_log) 
llegadas_tbl_2 <- llegadas_tbl %>% 
  filter(state_abbr %in% estados) %>%
  ungroup %>% 
  mutate(grupo_ln = cut_number(LISTA_NOMINAL, 3)) %>% 
  mutate(tiempo_huso = ifelse(tiempo - huso > 0, 
                              tiempo - huso, 0.001)) %>% 
  mutate(ln_log_c = lista_nominal_log - mean(lista_nominal_log)) 

reg_2 <- survreg(Surv(tiempo_huso, status) ~ 1 +
      ln_log_c +
      tipo_casilla +
      tipo_seccion +
      state_abbr:tipo_casilla + 
      state_abbr:log(1+RAC_1/(TOTAL_VOTOS_CALCULADOS + 1)) + 
      state_abbr:log(1+AMLO_1/(TOTAL_VOTOS_CALCULADOS + 1)) +          state_abbr:log(1+JAMK_1/(TOTAL_VOTOS_CALCULADOS +  1)) +
      state_abbr:ln_log_c + 
      state_abbr:tipo_seccion + 
      strata(state_abbr), 
    llegadas_tbl_2, 
    dist='loglogistic', 
    control = survreg.control(maxiter = 5000))
```

Los coeficientes y escalas para cada estado son:

```{r}
reg_2 %>% tidy() %>%  
  mutate(across(is.numeric, ~round(., 3))) %>%
  DT::datatable()
reg_2$scale
```

### Diagnósticos

Checamos simulaciones del modelo con la misma muestra para ver el ajuste a
total. En gris están las simulaciones y en rojo los datos observados de las
remesas:

```{r, echo = FALSE, fig.width=8, fig.height=10}
datos_sim <- map(1:70, ~ simular_cuantiles(.x, llegadas_tbl_2, reg_2)) 
gg_obs <- ggsurvplot(survfit(Surv(tiempo_huso, status)~ state_abbr, llegadas_tbl_2))
datos_obs <- gg_obs$data.survplot %>% mutate(id = 71)
datos_check <- bind_rows(datos_obs, datos_sim)
ggplot(datos_check %>% filter(id!=71), aes(x = time, y = surv, group = id)) +
  geom_hline(yintercept = 0.50, colour = "gray") +
  geom_step( alpha = 0.3, colour = "gray") +
  geom_step(data = datos_check %>% filter(id==71), colour = "red") +
  facet_wrap(~ strata) 
```

## Evaluación de tamaño de muestra y hora de salida

Ahora simulamos muestras de distintos tamaños, con horas de llegada. Hacemos
cortes en distintos tiempos

-   Muestras más grandes acumulan más muestra antes, lo cual reduce su varianza
-   Evaluamos en cada hora de salida el sesgo, varianza y error cuadrático medio
    de los estimadores puntuales.

En este ejemplo consideraremos la proporción de voto estimado para RAC en
Michoacán

```{r}
# cortes (horas después de 18:30 en la elección de 2018)
cortes <- c(1.5, 2.5, 3, 3.5, 4, 4.5, 5.5)
# tamaño de muestra
props_muestra <- c(0.05, 0.10, 0.20)
estado_sim <- "CHIH"
```

```{r, echo = FALSE}
simular_cortes <-  function(rep, cortes = cortes, prop_muestra = 0.3, estado_sim){
  # seleccionar una muestra y simular tiempos de llegadas
  muestra_tbl <- seleccionar_muestra(conteo, prop = prop_muestra, estado = estado_sim)
  tiempos_sim <- simular_cuantiles(1, muestra_tbl, reg_2, solo_tiempos = TRUE)
  datos <- bind_cols(tiempos_sim, muestra_tbl %>% select(-state_abbr)) %>%
        arrange(tiempo) %>% 
        pivot_longer(cols = all_of(c("AMLO_1", "RAC_1", "JAMK_1")), 
                     names_to = "candidato", values_to ="num_votos") %>% 
        group_by(candidato) %>% 
        mutate(acumulado_cand = cumsum(num_votos), 
               acumulado_tot = cumsum(TOTAL_VOTOS_CALCULADOS),
               num_casillas = row_number()) %>% 
        mutate(prop_cand = acumulado_cand / acumulado_tot)
  evaluacion_tbl <- map(cortes, function(corte) {  
      # calcular props para cada corte 
      # tomar ultimos datos
      props_corte <- datos %>% filter(tiempo <= corte) %>% 
      select(candidato, prop_cand, tiempo, acumulado_tot) %>% 
      slice(n()) %>% rename(hora_salida = tiempo) %>% 
      mutate(corte = corte, prop_muestra = prop_muestra)
      props_corte
    }) %>% 
    bind_rows %>% # unir todos los cortes 
    mutate(rep = rep)
}
sim_1 <- simular_cortes(1, cortes = cortes, prop_muestra = 0.05, 
                        estado_sim = estado_sim)
sim_1
```

```{r}
eval_tbl_1 <- map_df(1:300, ~ simular_cortes(.x, cortes= cortes, prop_muestra = 0.05,
                                             estado_sim = estado_sim))
eval_tbl_2 <- map_df(1:300, ~ simular_cortes(.x, cortes= cortes, prop_muestra = 0.10,
                                             estado_sim = estado_sim))
eval_tbl_3 <- map_df(1:300, ~ simular_cortes(.x, cortes= cortes, prop_muestra = 0.20,
                                             estado_sim = estado_sim))
```

```{r, echo = FALSE}
evals_tbl <- bind_rows(eval_tbl_1, eval_tbl_2, eval_tbl_3)
```

En primer lugar, **el error cuadrático medio es menor si se selecciona una
muestra inicial más grande**, y se reduce conforme la hora de censura es más
tarde:

```{r, echo = FALSE}
total <- seleccionar_muestra(conteo, prop = 1, estado_sim)
prop_obs_tbl <- total %>% 
  pivot_longer(cols = all_of(c("AMLO_1", "RAC_1", "JAMK_1")), 
               names_to = "candidato", values_to ="num_votos") %>% 
  group_by(candidato, state_abbr) %>% 
  summarise(acumulado_cand = sum(num_votos), 
            acumulado_tot = sum(TOTAL_VOTOS_CALCULADOS),
            .groups = "drop") %>% 
  mutate(prop_obs = acumulado_cand / acumulado_tot) %>% 
  select(state_abbr, candidato, prop_obs)
prop_obs_tbl
```

```{r, echo = FALSE}
ecm_tbl <- evals_tbl %>% 
  left_join(prop_obs_tbl) %>% 
  ungroup() %>% 
  group_by(corte, prop_muestra, candidato) %>% 
  summarise(sesgo = mean(prop_cand) - mean(prop_obs),
            varianza = var(prop_cand)) %>% 
  ungroup %>% 
  mutate(recm = sqrt(sesgo^2 + varianza)) %>% 
  mutate(prop_muestra = factor(prop_muestra))
ecm_tbl
```

```{r, echo = FALSE, fig.height = 4, fig.width = 10}
ggplot(ecm_tbl, aes(x = corte, y = recm, 
                    colour = prop_muestra, 
                    group=prop_muestra)) +
  geom_vline(xintercept = 4, colour = "gray30") +
  geom_point() + geom_line() +
  ylab("Raíz de Error Cuadrático Medio") + 
  xlab("Hora de censura (horas después de 18:30)") +
  facet_wrap(~candidato)
```

Sin embargo, la **proporción del error que se debe a sesgo es más grande cuanto
más grande sea la muestra inicial**:

```{r, echo = FALSE, fig.height = 4, fig.width = 10}
ggplot(ecm_tbl, aes(x = corte, y = (sesgo) / sqrt(varianza), 
                    colour = prop_muestra, 
                    group=prop_muestra)) +
  geom_vline(xintercept = 4, colour = "gray50") +
  geom_point() + geom_line() + 
  ylab(expression(Sesgo / EE)) + 
  xlab("Hora de censura (horas después de 18:30)") +
  facet_wrap(~candidato)
```

```{r, echo = FALSE, fig.height = 4, fig.width = 10}
ecm_tbl %>% filter(corte == 4) %>%
  mutate(ee = sqrt(varianza)) %>% 
  select(corte, prop_muestra, candidato, sesgo, ee) %>% 
  arrange(candidato, prop_muestra)
```





## Estimaciones finales vs conteos

Usamos el supuesto de muestreo proporcional dentro de cada estado.

```{r}
prop_obs_tbl <- conteo %>% 
  pivot_longer(cols = all_of(c("AMLO_1", "RAC_1", "JAMK_1")), 
               names_to = "candidato", values_to ="num_votos") %>% 
  group_by(candidato, state_abbr) %>% 
  summarise(acumulado_cand = sum(num_votos, na.rm = T), 
            acumulado_tot = sum(TOTAL_VOTOS_CALCULADOS, na.rm = T),
            num_casillas = n(),
            .groups = "drop") %>% 
  mutate(prop_obs = acumulado_cand / acumulado_tot) %>% 
  select(state_abbr, candidato, prop_obs, num_casillas)
prop_obs_tbl
```

```{r}
prop_muestra_tbl <- llegadas_tbl %>% 
  filter(tiempo < 3) %>% 
  pivot_longer(cols = all_of(c("AMLO_1", "RAC_1", "JAMK_1")), 
               names_to = "candidato", values_to ="num_votos") %>% 
  group_by(candidato, state_abbr) %>% 
  summarise(acumulado_cand = sum(num_votos, na.rm = T), 
            acumulado_tot = sum(TOTAL_VOTOS_CALCULADOS, na.rm = T),
            .groups = "drop") %>% 
  mutate(prop_muestra = acumulado_cand / acumulado_tot) %>% 
  select(state_abbr, candidato, prop_muestra)
prop_muestra_tbl
```

```{r}
comparacion_tbl <- left_join(prop_obs_tbl, prop_muestra_tbl) %>% 
  mutate(dif = 100*(prop_muestra - prop_obs)) %>% 
  ungroup %>% 
  group_by(candidato) %>% 
  arrange(candidato, dif) %>%
  mutate(across(is.numeric, ~ round(., 3))) 
comparacion_tbl %>% 
  DT::datatable()
```

```{r}
ggplot(comparacion_tbl, aes(x = candidato, y = dif, size = num_casillas)) +
  geom_jitter(width = 0.1, height = 0.0) + 
  stat_summary(fun = mean, geom = "point", 
               shape = 20, size = 8, color = "red", fill = "red") +
  coord_flip() + geom_hline(yintercept = 0, colour = "red") +
  ylab("Diferencia Computos (Muestra obs ´vs Total)") 
```
